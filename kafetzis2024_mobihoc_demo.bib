@inproceedings{Kafetzis2024MobiHocDemo,
  author = {Kafetzis, Dimitrios and Koutsopoulos, Iordanis},
  title = {Demo: An Experimental Platform for AI Model Partitioning on Resource-constrained Devices},
  year = {2024},
  isbn = {9798400705212},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3641512.3690629},
  doi = {10.1145/3641512.3690629},
  abstract = {Partitioning Artificial Intelligence (AI) models such as Deep Neural Networks (DNNs) or Transformer-based Architectures is essential for minimizing latency in resource-constrained edge computing environments, which is critical for applications such as real-time video analytics, autonomous vehicles, smart IoT systems, and most importantly, on-device Large Language Models (LLMs)1. This paper presents a demonstration of an experimental platform showcased for DNN partitioning for the inference stage, which comprises a WiFi network of Raspberry Pi 4 devices. The platform supports research on optimizing inference in distributed setups, focusing on performance and resource usage and it can support several architectures, ranging from simple and deep NNs, to more advanced transformer-based architectures.},
  booktitle = {Proceedings of the Twenty-Fifth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
  pages = {375â€“376},
  numpages = {2},
  keywords = {NN architecture partitioning, inference, edge computing, resource-constrained devices, experimental platform},
  location = {Athens, Greece},
  series = {MobiHoc '24}
}
